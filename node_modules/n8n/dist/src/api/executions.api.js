"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.executionsController = void 0;
const express_1 = __importDefault(require("express"));
const jsonschema_1 = require("jsonschema");
const lodash_1 = require("lodash");
const n8n_core_1 = require("n8n-core");
const n8n_workflow_1 = require("n8n-workflow");
const typeorm_1 = require("typeorm");
const __1 = require("..");
const config = __importStar(require("../../config"));
const GenericHelpers_1 = require("../GenericHelpers");
const Logger_1 = require("../Logger");
const Queue = __importStar(require("../Queue"));
const WorkflowHelpers_1 = require("../WorkflowHelpers");
exports.executionsController = express_1.default.Router();
const schemaGetExecutionsQueryFilter = {
    $id: '/IGetExecutionsQueryFilter',
    type: 'object',
    properties: {
        finished: { type: 'boolean' },
        mode: { type: 'string' },
        retryOf: { type: 'string' },
        retrySuccessId: { type: 'string' },
        waitTill: { type: 'boolean' },
        workflowId: { anyOf: [{ type: 'integer' }, { type: 'string' }] },
    },
};
const allowedExecutionsQueryFilterFields = Object.keys(schemaGetExecutionsQueryFilter.properties);
exports.executionsController.use((req, res, next) => {
    try {
        n8n_workflow_1.LoggerProxy.getInstance();
    }
    catch (error) {
        n8n_workflow_1.LoggerProxy.init((0, Logger_1.getLogger)());
    }
    next();
});
async function getExecutionsCount(countFilter, user) {
    const dbType = (await __1.GenericHelpers.getConfigValue('database.type'));
    const filteredFields = Object.keys(countFilter).filter((field) => field !== 'id');
    if (dbType !== 'postgresdb' || filteredFields.length > 0 || user.globalRole.name !== 'owner') {
        const sharedWorkflowIds = await (0, WorkflowHelpers_1.getSharedWorkflowIds)(user);
        const count = await __1.Db.collections.Execution.count({
            where: {
                workflowId: (0, typeorm_1.In)(sharedWorkflowIds),
                ...countFilter,
            },
        });
        return { count, estimated: false };
    }
    try {
        const estimateRowsNumberSql = "SELECT n_live_tup FROM pg_stat_all_tables WHERE relname = 'execution_entity';";
        const rows = await __1.Db.collections.Execution.query(estimateRowsNumberSql);
        const estimate = parseInt(rows[0].n_live_tup, 10);
        if (estimate > 100000) {
            return { count: estimate, estimated: true };
        }
    }
    catch (error) {
        n8n_workflow_1.LoggerProxy.warn(`Failed to get executions count from Postgres: ${error}`);
    }
    const sharedWorkflowIds = await (0, WorkflowHelpers_1.getSharedWorkflowIds)(user);
    const count = await __1.Db.collections.Execution.count({
        where: {
            workflowId: (0, typeorm_1.In)(sharedWorkflowIds),
        },
    });
    return { count, estimated: false };
}
exports.executionsController.get('/', __1.ResponseHelper.send(async (req) => {
    const sharedWorkflowIds = await (0, WorkflowHelpers_1.getSharedWorkflowIds)(req.user);
    if (sharedWorkflowIds.length === 0) {
        return {
            count: 0,
            estimated: false,
            results: [],
        };
    }
    let filter = undefined;
    if (req.query.filter) {
        try {
            const filterJson = (0, n8n_workflow_1.jsonParse)(req.query.filter);
            if (filterJson) {
                Object.keys(filterJson).map((key) => {
                    if (!allowedExecutionsQueryFilterFields.includes(key))
                        delete filterJson[key];
                });
                if ((0, jsonschema_1.validate)(filterJson, schemaGetExecutionsQueryFilter).valid) {
                    filter = filterJson;
                }
            }
        }
        catch (error) {
            n8n_workflow_1.LoggerProxy.error('Failed to parse filter', {
                userId: req.user.id,
                filter: req.query.filter,
            });
            throw new __1.ResponseHelper.ResponseError(`Parameter "filter" contained invalid JSON string.`, 500, 500);
        }
    }
    if ((filter === null || filter === void 0 ? void 0 : filter.workflowId) !== undefined) {
        const workflowId = parseInt(filter.workflowId.toString());
        if (workflowId && !sharedWorkflowIds.includes(workflowId)) {
            n8n_workflow_1.LoggerProxy.verbose(`User ${req.user.id} attempted to query non-shared workflow ${workflowId}`);
            return {
                count: 0,
                estimated: false,
                results: [],
            };
        }
    }
    const limit = req.query.limit
        ? parseInt(req.query.limit, 10)
        : GenericHelpers_1.DEFAULT_EXECUTIONS_GET_ALL_LIMIT;
    const executingWorkflowIds = [];
    if (config.getEnv('executions.mode') === 'queue') {
        const currentJobs = await Queue.getInstance().getJobs(['active', 'waiting']);
        executingWorkflowIds.push(...currentJobs.map(({ data }) => data.executionId));
    }
    executingWorkflowIds.push(...__1.ActiveExecutions.getInstance()
        .getActiveExecutions()
        .map(({ id }) => id));
    const findWhere = { workflowId: (0, typeorm_1.In)(sharedWorkflowIds) };
    const rangeQuery = [];
    const rangeQueryParams = {};
    if (req.query.lastId) {
        rangeQuery.push('id < :lastId');
        rangeQueryParams.lastId = req.query.lastId;
    }
    if (req.query.firstId) {
        rangeQuery.push('id > :firstId');
        rangeQueryParams.firstId = req.query.firstId;
    }
    if (executingWorkflowIds.length > 0) {
        rangeQuery.push(`id NOT IN (:...executingWorkflowIds)`);
        rangeQueryParams.executingWorkflowIds = executingWorkflowIds;
    }
    if (rangeQuery.length) {
        Object.assign(findWhere, {
            id: (0, typeorm_1.Raw)(() => rangeQuery.join(' and '), rangeQueryParams),
        });
    }
    let query = __1.Db.collections.Execution.createQueryBuilder()
        .select()
        .orderBy('id', 'DESC')
        .take(limit)
        .where(findWhere);
    if (filter) {
        if (filter.waitTill === true) {
            filter.waitTill = (0, typeorm_1.Not)((0, typeorm_1.IsNull)());
        }
        else if (filter.finished === false) {
            filter.waitTill = (0, typeorm_1.IsNull)();
        }
        else {
            delete filter.waitTill;
        }
        query = query.andWhere(filter);
    }
    const countFilter = (0, lodash_1.cloneDeep)(filter !== null && filter !== void 0 ? filter : {});
    countFilter.id = (0, typeorm_1.Not)((0, typeorm_1.In)(executingWorkflowIds));
    const executions = await query.getMany();
    const { count, estimated } = await getExecutionsCount(countFilter, req.user);
    const formattedExecutions = executions.map((execution) => {
        var _a, _b, _c, _d, _e, _f;
        return {
            id: execution.id.toString(),
            finished: execution.finished,
            mode: execution.mode,
            retryOf: (_a = execution.retryOf) === null || _a === void 0 ? void 0 : _a.toString(),
            retrySuccessId: (_b = execution === null || execution === void 0 ? void 0 : execution.retrySuccessId) === null || _b === void 0 ? void 0 : _b.toString(),
            waitTill: execution.waitTill,
            startedAt: execution.startedAt,
            stoppedAt: execution.stoppedAt,
            workflowId: (_e = (_d = (_c = execution.workflowData) === null || _c === void 0 ? void 0 : _c.id) === null || _d === void 0 ? void 0 : _d.toString()) !== null && _e !== void 0 ? _e : '',
            workflowName: (_f = execution.workflowData) === null || _f === void 0 ? void 0 : _f.name,
        };
    });
    return {
        count,
        results: formattedExecutions,
        estimated,
    };
}));
exports.executionsController.get('/:id', __1.ResponseHelper.send(async (req) => {
    const { id: executionId } = req.params;
    const sharedWorkflowIds = await (0, WorkflowHelpers_1.getSharedWorkflowIds)(req.user);
    if (!sharedWorkflowIds.length)
        return undefined;
    const execution = await __1.Db.collections.Execution.findOne({
        where: {
            id: executionId,
            workflowId: (0, typeorm_1.In)(sharedWorkflowIds),
        },
    });
    if (!execution) {
        n8n_workflow_1.LoggerProxy.info('Attempt to read execution was blocked due to insufficient permissions', {
            userId: req.user.id,
            executionId,
        });
        return undefined;
    }
    if (req.query.unflattedResponse === 'true') {
        return __1.ResponseHelper.unflattenExecutionData(execution);
    }
    const { id, ...rest } = execution;
    return {
        id: id.toString(),
        ...rest,
    };
}));
exports.executionsController.post('/:id/retry', __1.ResponseHelper.send(async (req) => {
    const { id: executionId } = req.params;
    const sharedWorkflowIds = await (0, WorkflowHelpers_1.getSharedWorkflowIds)(req.user);
    if (!sharedWorkflowIds.length)
        return false;
    const execution = await __1.Db.collections.Execution.findOne({
        where: {
            id: executionId,
            workflowId: (0, typeorm_1.In)(sharedWorkflowIds),
        },
    });
    if (!execution) {
        n8n_workflow_1.LoggerProxy.info('Attempt to retry an execution was blocked due to insufficient permissions', {
            userId: req.user.id,
            executionId,
        });
        throw new __1.ResponseHelper.ResponseError(`The execution with the ID "${executionId}" does not exist.`, 404, 404);
    }
    const fullExecutionData = __1.ResponseHelper.unflattenExecutionData(execution);
    if (fullExecutionData.finished) {
        throw new Error('The execution succeeded, so it cannot be retried.');
    }
    const executionMode = 'retry';
    fullExecutionData.workflowData.active = false;
    const data = {
        executionMode,
        executionData: fullExecutionData.data,
        retryOf: req.params.id,
        workflowData: fullExecutionData.workflowData,
        userId: req.user.id,
    };
    const { lastNodeExecuted } = data.executionData.resultData;
    if (lastNodeExecuted) {
        delete data.executionData.resultData.error;
        const { length } = data.executionData.resultData.runData[lastNodeExecuted];
        if (length > 0 &&
            data.executionData.resultData.runData[lastNodeExecuted][length - 1].error !== undefined) {
            data.executionData.resultData.runData[lastNodeExecuted].pop();
        }
    }
    if (req.body.loadWorkflow) {
        const workflowId = fullExecutionData.workflowData.id;
        const workflowData = (await __1.Db.collections.Workflow.findOne(workflowId));
        if (workflowData === undefined) {
            throw new Error(`The workflow with the ID "${workflowId}" could not be found and so the data not be loaded for the retry.`);
        }
        data.workflowData = workflowData;
        const nodeTypes = (0, __1.NodeTypes)();
        const workflowInstance = new n8n_workflow_1.Workflow({
            id: workflowData.id,
            name: workflowData.name,
            nodes: workflowData.nodes,
            connections: workflowData.connections,
            active: false,
            nodeTypes,
            staticData: undefined,
            settings: workflowData.settings,
        });
        for (const stack of data.executionData.executionData.nodeExecutionStack) {
            const node = workflowInstance.getNode(stack.node.name);
            if (node === null) {
                n8n_workflow_1.LoggerProxy.error('Failed to retry an execution because a node could not be found', {
                    userId: req.user.id,
                    executionId,
                    nodeName: stack.node.name,
                });
                throw new Error(`Could not find the node "${stack.node.name}" in workflow. It probably got deleted or renamed. Without it the workflow can sadly not be retried.`);
            }
            stack.node = node;
        }
    }
    const workflowRunner = new __1.WorkflowRunner();
    const retriedExecutionId = await workflowRunner.run(data);
    const executionData = await __1.ActiveExecutions.getInstance().getPostExecutePromise(retriedExecutionId);
    if (!executionData) {
        throw new Error('The retry did not start for an unknown reason.');
    }
    return !!executionData.finished;
}));
exports.executionsController.post('/delete', __1.ResponseHelper.send(async (req) => {
    const { deleteBefore, ids, filters: requestFiltersRaw } = req.body;
    let requestFilters;
    if (requestFiltersRaw) {
        try {
            Object.keys(requestFiltersRaw).map((key) => {
                if (!allowedExecutionsQueryFilterFields.includes(key))
                    delete requestFiltersRaw[key];
            });
            if ((0, jsonschema_1.validate)(requestFiltersRaw, schemaGetExecutionsQueryFilter).valid) {
                requestFilters = requestFiltersRaw;
            }
        }
        catch (error) {
            throw new __1.ResponseHelper.ResponseError(`Parameter "filter" contained invalid JSON string.`, 500, 500);
        }
    }
    if (!deleteBefore && !ids) {
        throw new Error('Either "deleteBefore" or "ids" must be present in the request body');
    }
    const sharedWorkflowIds = await (0, WorkflowHelpers_1.getSharedWorkflowIds)(req.user);
    if (sharedWorkflowIds.length === 0) {
        return;
    }
    const binaryDataManager = n8n_core_1.BinaryDataManager.getInstance();
    if (deleteBefore) {
        const filters = {
            startedAt: (0, typeorm_1.LessThanOrEqual)(deleteBefore),
        };
        let query = __1.Db.collections.Execution.createQueryBuilder()
            .select()
            .where({
            ...filters,
            workflowId: (0, typeorm_1.In)(sharedWorkflowIds),
        });
        if (requestFilters) {
            query = query.andWhere(requestFilters);
        }
        const executions = await query.getMany();
        if (!executions.length)
            return;
        const idsToDelete = executions.map(({ id }) => id.toString());
        await Promise.all(idsToDelete.map(async (id) => binaryDataManager.deleteBinaryDataByExecutionId(id)));
        await __1.Db.collections.Execution.delete({ id: (0, typeorm_1.In)(idsToDelete) });
        return;
    }
    if (ids) {
        const executions = await __1.Db.collections.Execution.find({
            where: {
                id: (0, typeorm_1.In)(ids),
                workflowId: (0, typeorm_1.In)(sharedWorkflowIds),
            },
        });
        if (!executions.length) {
            n8n_workflow_1.LoggerProxy.error('Failed to delete an execution due to insufficient permissions', {
                userId: req.user.id,
                executionIds: ids,
            });
            return;
        }
        const idsToDelete = executions.map(({ id }) => id.toString());
        await Promise.all(idsToDelete.map(async (id) => binaryDataManager.deleteBinaryDataByExecutionId(id)));
        await __1.Db.collections.Execution.delete(idsToDelete);
    }
}));
//# sourceMappingURL=executions.api.js.map